
### iMAP: Integration of Multiple single-cell datasets by Adversarial Paired-style transfer networks {#ch-5-2-3}

iMAP [@RN123]<!--[67]--> combines AE and GAN for batch effect removal. It is designed to remove batch biases while preserving dataset-specific biological variations. 

*Model.*  iMAP consists of two processing stages, each including a separate DL model. In the first stage, a special AE, whose decoder combines the output of two separate decoders $D_{\theta_{1}}$ and $D_{\theta_{2}}, is trained such that

\begin{equation}
z_{n} = E_{\phi}; \hat{x}_{n}=D_{\theta}(z_{n},s_{n}) = ReLu(D_{\theta_{1}}(s_{n}) + D_{\theta_{2}}(z_{n}, s_{n})) (\#eq:eq23)
\end{equation}

where $s_{n}$ is the one-hot encoded batch number of cell $n$.  $D_{θ_{1}} can be understood as decoding the batch noise, whereas $D_{θ_{2}} reconstructs batch-removed expression from the latent variable $z_{n}$. The training minimizes the loss

\begin{equation}
L(\Theta)=L_{0}(\Theta)+\gamma L_{t}(\Theta) (\#eq:eq24)
\end{equation}

where  $L_{0}(\Theta)$ is the MSE reconstruction loss defined in eq. (\@ref(eq:eq7)) and $L_{c}$ is the content loss

\begin{equation}
L_{t}(\Theta)= \sum_{n=1}^{N} \| z_{n}-E_{\phi}(D_{\theta}(z_{n},\tilde{s}_{n})) \|_{2}^{2} (\#eq:eq25)
\end{equation}

where $\tilde{s_{n}}$ is a random batch number. Minimizing $L_{t}(\Theta)$ further ensures the reconstructed expression $\hat{x_{n}}$ would be batch agnostic and has the same content as $x_{n}$. 
However, the author indicated that due to the limitation of AE, this step is still insufficient for batch removal. Therefore, a second stage is included to apply a GAN model to make expression distributions of the shared cell type across different baches indistinguishable. To identified the shared cell types, a mutual nearest neighbors (MNN) strategy adapted from [@RN84]<!--[28]--> was developed to identify MNN pairs across batches using batch effect independent  $z_{n}$ as opposed to $x_{n}$. Then, a mapping generator $G_{\theta_{G}}$ is trained using MNN pairs based on GAN such that $x_{n}^{(A)} =G_{\theta_{G}}(x_{n}^{(s)})$, where $x_{n}^{(S)}$ and $x_{n}^{(A)}$  are the MNN pairs from batch $S$ and an anchor batch $A$. The WGAN-GP loss as in Eq. (\@ref(eq:eq10)) was adopted for the GAN training. After training, $G_{\theta_{G}}$ is applied to all cells of a batch to generate batch-corrected expression.   

*Evaluation matrics.* The classifier-based metric as described in section \@ref(ch-4-2-2) was used.

*Results:* iMAP was first tested on benchmark datasets from human dendritic cells and Jurkat and 293T cell lines and then human pancreas datasets from five different platforms. All the datasets contain both batch-specific cells and batch-shared cell types. iMAP was shown to separate the batch-specific cell types but mix batch shared cell types and outperformed 9 other existing batch correction methods including Harmony, scVI, fastMNN, Seurat, etc. iMAP was then applied to the large-scale Tabula Muris datasets containing over 100K cells sequenced from two platforms. iMAP could not only reliably integrate cells from the same tissues but identify cells from platform-specific tissues. Finally, iMAP was applied to datasets of tumor-infiltrating immune cells and shown to reduce the dropout ratio and the percentage of ribosomal genes and noncoding RNAs, thus improving detection of rare cell types and ligand-receptor interactions. iMAP scales with the number of cells, showing minimal time cost increase after the number of cells exceeds thousands. Its performance is also robust against model hyperparameters.











